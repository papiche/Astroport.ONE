#!/usr/bin/env python3
"""
Script pour cr√©er des cha√Ænes vid√©o √† partir des messages NOSTR
Utilise les tags et m√©tadonn√©es pour grouper les vid√©os par cha√Æne
Peut r√©cup√©rer des √©v√©nements NOSTR directement depuis un relay
"""

import json
import sys
import argparse
import asyncio
import websockets
import base64
import hashlib
import hmac
import subprocess
import os
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
import re

async def fetch_nostr_events(relay_url: str = "ws://127.0.0.1:7777", limit: int = 100) -> List[Dict[str, Any]]:
    """
    R√©cup√®re les √©v√©nements NOSTR depuis un relay
    """
    events = []
    
    try:
        async with websockets.connect(relay_url) as websocket:
            # Requ√™te pour r√©cup√©rer uniquement les √©v√©nements NIP-71 (kind: 21, 22)
            filter_data = {
                "kinds": [21, 22],  # NIP-71 Video Events uniquement (normal + shorts)
                "limit": limit,
                "#t": ["YouTubeDownload", "VideoChannel"]
            }
            
            request = ["REQ", "youtube_videos", filter_data]
            await websocket.send(json.dumps(request))
            
            # √âcouter les r√©ponses
            async for message in websocket:
                try:
                    data = json.loads(message)
                    if data[0] == "EVENT":
                        event = data[2]
                        # V√©rifier si c'est un √©v√©nement de vid√©o YouTube
                        if is_youtube_video_event(event):
                            events.append(event)
                    elif data[0] == "EOSE":
                        break
                except (json.JSONDecodeError, IndexError, KeyError):
                    continue
                    
    except Exception as e:
        print(f"Erreur lors de la r√©cup√©ration des √©v√©nements NOSTR: {e}")
    
    return events

def is_youtube_video_event(event: Dict[str, Any]) -> bool:
    """
    V√©rifie si un √©v√©nement NOSTR est une vid√©o YouTube NIP-71
    Supporte uniquement les √©v√©nements kind: 21 et 22 (NIP-71)
    """
    tags = event.get('tags', [])
    kind = event.get('kind', 1)
    
    # Accepter uniquement les √©v√©nements NIP-71 (kind: 21 ou 22)
    if kind not in [21, 22]:
        return False
    
    # V√©rifier les tags NIP-71 pour les vid√©os
    has_video_tags = any(tag[0] == 'url' and ('ipfs' in tag[1] or 'youtube' in tag[1]) for tag in tags if len(tag) > 1)
    has_media_type = any(tag[0] == 'm' and 'video' in tag[1] for tag in tags if len(tag) > 1)
    
    return has_video_tags and has_media_type

def extract_video_info_from_nostr_event(event: Dict[str, Any]) -> Dict[str, Any]:
    """
    Extrait les informations vid√©o d'un √©v√©nement NOSTR NIP-71
    Supporte uniquement les √©v√©nements kind: 21 et 22 (NIP-71)
    """
    content = event.get('content', '')
    tags = event.get('tags', [])
    kind = event.get('kind', 21)  # Default to NIP-71
    
    # Extraire les liens IPFS et YouTube depuis les tags NIP-71
    ipfs_url = ""
    youtube_url = ""
    metadata_ipfs = ""
    thumbnail_ipfs = ""
    
    # Parse imeta tags (NIP-71 format)
    for tag in tags:
        if len(tag) >= 2:
            tag_type = tag[0]
            tag_value = tag[1]
            
            if tag_type == 'imeta':
                # Parse imeta properties
                for prop in tag[1:]:
                    if prop.startswith('dim '):
                        dimensions = prop[4:]
                    elif prop.startswith('url '):
                        ipfs_url = prop[4:]
                    elif prop.startswith('x '):
                        file_hash = prop[2:]
                    elif prop.startswith('m '):
                        media_type = prop[2:]
                    elif prop.startswith('image '):
                        thumbnail_ipfs = prop[6:]
                    elif prop.startswith('fallback '):
                        fallback_url = prop[9:]
                    elif prop.startswith('service '):
                        service_type = prop[8:]
            elif tag_type == 'url':
                if 'youtube.com' in tag_value or 'youtu.be' in tag_value:
                    youtube_url = tag_value
                elif '/ipfs/' in tag_value or 'ipfs://' in tag_value:
                    ipfs_url = tag_value
            elif tag_type == 'm' and 'video' in tag_value:
                # Media type confirmed as video
                pass
            elif tag_type == 'size' and tag_value.isdigit():
                # File size from NIP-71
                pass
            elif tag_type == 'duration' and tag_value.isdigit():
                # Duration from NIP-71
                pass
            elif tag_type == 'dim':
                dimensions = tag_value
    
    # Fallback: Parser le contenu si les tags ne contiennent pas les infos
    if not ipfs_url:
        ipfs_match = re.search(r'üîó IPFS: (https?://[^\s]+)', content)
        if ipfs_match:
            ipfs_url = ipfs_match.group(1)
    
    if not youtube_url:
        youtube_match = re.search(r'üì∫ YouTube: (https?://[^\s]+)', content)
        if youtube_match:
            youtube_url = youtube_match.group(1)
    
    if not metadata_ipfs:
        metadata_match = re.search(r'üìã M√©tadonn√©es: (https?://[^\s]+)', content)
        if metadata_match:
            metadata_ipfs = metadata_match.group(1)
    
    if not thumbnail_ipfs:
        thumbnail_match = re.search(r'üñºÔ∏è Miniature: (https?://[^\s]+)', content)
        if thumbnail_match:
            thumbnail_ipfs = thumbnail_match.group(1)
    
    # Extraire le titre et l'uploader
    title_match = re.search(r'üé¨ Nouvelle vid√©o t√©l√©charg√©e: ([^par]+) par ([^\n]+)', content)
    title = title_match.group(1).strip() if title_match else "Titre inconnu"
    uploader = title_match.group(2).strip() if title_match else "Auteur inconnu"
    
    # Extraire les sous-titres
    subtitles = []
    subtitle_matches = re.findall(r'‚Ä¢ ([a-z]{2}) \([a-z]+\): (https?://[^\s]+)', content)
    for lang, url in subtitle_matches:
        subtitles.append({
            "language": lang,
            "url": url,
            "format": "vtt" if "vtt" in url else "srt"
        })
    
    # Extraire les tags de cha√Æne
    channel_tags = [t[1] for t in tags if len(t) > 1 and t[1].startswith('Channel-')]
    if channel_tags:
        channel_name = channel_tags[0].replace('Channel-', '')
    elif uploader and uploader != "null":
        # Use uploader as channel name if no Channel tag found
        channel_name = uploader.replace(' ', '_').replace('-', '_')
    else:
        channel_name = "unknown"
    
    # Extraire les tags de sujet
    topic_tags = [t[1] for t in tags if len(t) > 1 and t[1].startswith('Topic-')]
    topic_keywords = [tag.replace('Topic-', '') for tag in topic_tags]
    
    # Extraire la dur√©e et la taille de fichier depuis les tags NIP-71
    duration = 0
    file_size = 0
    dimensions = ""
    
    # Extraire les coordonn√©es g√©ographiques depuis les tags NOSTR
    latitude = None
    longitude = None
    
    # Extraire les m√©tadonn√©es NIP-71 uniquement
    for tag in tags:
        if len(tag) >= 2:
            tag_type = tag[0]
            tag_value = tag[1]
            
            if tag_type == 'duration':
                try:
                    duration = int(tag_value)
                except ValueError:
                    duration = 0
            elif tag_type == 'size':
                try:
                    file_size = int(tag_value)
                except ValueError:
                    file_size = 0
            elif tag_type == 'dim':
                dimensions = tag_value
            elif tag_type == 'g':
                # Geohash tag format: "lat,lon"
                try:
                    coords = tag_value.split(',')
                    if len(coords) == 2:
                        latitude = float(coords[0].strip())
                        longitude = float(coords[1].strip())
                except (ValueError, IndexError):
                    pass
            elif tag_type == 'latitude':
                # Separate latitude tag
                try:
                    latitude = float(tag_value)
                except ValueError:
                    pass
            elif tag_type == 'longitude':
                # Separate longitude tag
                try:
                    longitude = float(tag_value)
                except ValueError:
                    pass
            elif tag_type == 'location':
                # Human-readable location tag format: "lat,lon"
                if latitude is None or longitude is None:  # Only use if not already set
                    try:
                        coords = tag_value.split(',')
                        if len(coords) == 2:
                            latitude = float(coords[0].strip())
                            longitude = float(coords[1].strip())
                    except (ValueError, IndexError):
                        pass
    
    return {
        'title': title,
        'uploader': uploader,
        'ipfs_url': ipfs_url,
        'youtube_url': youtube_url,  # Utilise youtube_url pour la coh√©rence
        'original_url': youtube_url,  # Alias pour compatibilit√© avec process_youtube.sh
        'metadata_ipfs': metadata_ipfs,
        'thumbnail_ipfs': thumbnail_ipfs,
        'subtitles': subtitles,
        'channel_name': channel_name,
        'topic_keywords': ','.join(topic_keywords),
        'message_id': event.get('id', ''),
        'author_id': event.get('pubkey', ''),
        'created_at': datetime.fromtimestamp(event.get('created_at', 0)).isoformat(),
        'download_date': datetime.fromtimestamp(event.get('created_at', 0)).isoformat(),  # Alias pour compatibilit√©
        'duration': duration,  # Extrait depuis les tags NOSTR
        'file_size': file_size,  # Extrait depuis les tags NOSTR
        'dimensions': dimensions,  # Nouvelles dimensions NIP-71
        'latitude': latitude,  # Latitude extraite depuis les tags NOSTR
        'longitude': longitude,  # Longitude extraite depuis les tags NOSTR
        'event_kind': kind,  # Type d'√©v√©nement (1 ou 21)
        'technical_info': {
            'download_date': datetime.fromtimestamp(event.get('created_at', 0)).isoformat(),
            'file_size': file_size,
            'dimensions': dimensions
        }
    }

def parse_nostr_message(message_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    Parse un message NOSTR pour extraire les informations de vid√©o
    """
    # Extraire les informations de base
    video_info = {
        'title': message_data.get('title', ''),
        'uploader': message_data.get('uploader', ''),
        'duration': message_data.get('duration', 0),
        'ipfs_url': message_data.get('ipfs_url', ''),
        'youtube_url': message_data.get('original_url', ''),  # Compatible avec process_youtube.sh
        'thumbnail_ipfs': message_data.get('thumbnail_ipfs', ''),
        'metadata_ipfs': message_data.get('metadata_ipfs', ''),
        'download_date': message_data.get('technical_info', {}).get('download_date', ''),
        'file_size': message_data.get('technical_info', {}).get('file_size', 0),
        'subtitles': message_data.get('subtitles', []),  # Ajout des sous-titres
        'message_id': message_data.get('message_id', ''),
        'author_id': message_data.get('author_id', '')
    }
    
    # Extraire les informations de cha√Æne
    channel_info = message_data.get('channel_info', {})
    video_info['channel_name'] = channel_info.get('name', '')
    video_info['channel_display_name'] = channel_info.get('display_name', '')
    
    # Fallback: if no channel_info, use uploader as channel name
    if not video_info['channel_name'] and video_info.get('uploader'):
        video_info['channel_name'] = video_info['uploader'].replace(' ', '_').replace('-', '_')
    
    # Extraire les informations de contenu
    content_info = message_data.get('content_info', {})
    video_info['description'] = content_info.get('description', '')
    video_info['ai_analysis'] = content_info.get('ai_analysis', '')
    video_info['topic_keywords'] = content_info.get('topic_keywords', '')
    video_info['duration_category'] = content_info.get('duration_category', '')
    
    # Ajouter les nouvelles m√©tadonn√©es NIP-71
    video_info['dimensions'] = message_data.get('dimensions', '')
    video_info['event_kind'] = message_data.get('event_kind', 1)
    
    return video_info

def is_incompatible_youtube_message(event: Dict[str, Any]) -> bool:
    """
    D√©termine si un message YouTube NIP-71 est incompatible avec l'affichage youtube.html
    Un message est incompatible s'il manque des tags essentiels NIP-71
    Supporte uniquement les √©v√©nements kind: 21 et 22 (NIP-71)
    """
    tags = event.get('tags', [])
    kind = event.get('kind', 21)
    
    # Accepter uniquement les √©v√©nements NIP-71 (kind: 21 ou 22)
    if kind not in [21, 22]:
        return True  # Incompatible si ce n'est pas NIP-71
    
    # V√©rifier les tags NIP-71 essentiels
    has_video_url = False
    has_media_type = False
    
    for tag in tags:
        if len(tag) >= 2:
            tag_type = tag[0]
            tag_value = tag[1]
            
            if tag_type == 'url' and ('ipfs' in tag_value or 'youtube' in tag_value):
                has_video_url = True
            elif tag_type == 'm' and 'video' in tag_value:
                has_media_type = True
    
    return not (has_video_url and has_media_type)


def create_channel_playlist(videos: List[Dict[str, Any]], channel_name: str) -> Dict[str, Any]:
    """
    Cr√©er une playlist de cha√Æne √† partir d'une liste de vid√©os
    """
    # Validate and filter videos
    valid_videos = []
    for video in videos:
        if video.get('title') and video.get('ipfs_url'):
            valid_videos.append(video)
    
    videos = valid_videos
    
    # Trier les vid√©os par date de t√©l√©chargement
    videos.sort(key=lambda x: x.get('download_date', ''), reverse=True)
    
    # Calculer les statistiques de la cha√Æne
    total_duration = sum(int(v.get('duration', 0)) for v in videos)
    total_size = sum(int(v.get('file_size', 0)) for v in videos)
    
    # Extraire les mots-cl√©s communs
    all_keywords = []
    for video in videos:
        keywords = video.get('topic_keywords', '').split(',')
        all_keywords.extend([k.strip() for k in keywords if k.strip()])
    
    # Compter les mots-cl√©s
    from collections import Counter
    keyword_counts = Counter(all_keywords)
    common_keywords = [kw for kw, count in keyword_counts.most_common(10) if count > 1]
    
    channel_playlist = {
        'channel_info': {
            'name': channel_name,
            'display_name': videos[0].get('channel_display_name', '') if videos else '',
            'type': 'youtube',
            'created_date': datetime.now().isoformat(),
            'video_count': len(videos),
            'total_duration_seconds': total_duration,
            'total_duration_formatted': f"{total_duration // 3600}h {(total_duration % 3600) // 60}m",
            'total_size_bytes': total_size,
            'total_size_formatted': f"{total_size / (1024*1024*1024):.2f} GB",
            'common_keywords': common_keywords
        },
        'videos': videos,
        'playlist_url': f"ipfs://channel/{channel_name}",
        'export_formats': {
            'm3u': f"#EXTM3U\n#EXTINF:-1,{channel_name}\n" + "\n".join([v['ipfs_url'] for v in videos]),
            'json': json.dumps(videos, indent=2),
            'csv': "title,uploader,duration,ipfs_url,youtube_url\n" + 
                   "\n".join([f'"{v["title"]}","{v["uploader"]}",{v["duration"]},"{v["ipfs_url"]}","{v["youtube_url"]}"' for v in videos])
        }
    }
    
    return channel_playlist

async def fetch_and_process_nostr_events(relay_url: str = "ws://127.0.0.1:7777", limit: int = 100) -> List[Dict[str, Any]]:
    """
    R√©cup√®re et traite les √©v√©nements NOSTR NIP-71 pour cr√©er des cha√Ænes vid√©o
    Filtre automatiquement les messages incompatibles et affiche les statistiques
    Ne traite que les √©v√©nements kind: 21 et 22 (NIP-71)
    """
    events = await fetch_nostr_events(relay_url, limit)
    video_messages = []
    filtered_count = 0
    
    print(f"üìä Processing {len(events)} NIP-71 video events...")
    
    for event in events:
        # Filtrer les messages incompatibles
        if is_incompatible_youtube_message(event):
            filtered_count += 1
            continue
            
        video_info = extract_video_info_from_nostr_event(event)
        video_messages.append(video_info)
    
    print(f"‚úÖ {len(video_messages)} compatible NIP-71 messages")
    if filtered_count > 0:
        print(f"üîç {filtered_count} incompatible messages filtered out")
    
    return video_messages

def main():
    parser = argparse.ArgumentParser(description="Cr√©er des cha√Ænes vid√©o √† partir des messages NOSTR")
    parser.add_argument("--input", "-i", help="Fichier JSON contenant les messages NOSTR")
    parser.add_argument("--channel", "-c", help="Nom de la cha√Æne √† cr√©er")
    parser.add_argument("--output", "-o", help="Fichier de sortie pour la playlist")
    parser.add_argument("--format", "-f", choices=['json', 'm3u', 'csv'], default='json', help="Format de sortie")
    parser.add_argument("--relay", "-r", default="ws://127.0.0.1:7777", help="URL du relay NOSTR")
    parser.add_argument("--limit", "-l", type=int, default=100, help="Nombre maximum d'√©v√©nements √† r√©cup√©rer")
    parser.add_argument("--fetch-nostr", action="store_true", help="R√©cup√©rer les √©v√©nements depuis NOSTR au lieu d'un fichier")
    
    args = parser.parse_args()
    
    # Charger les donn√©es d'entr√©e
    if args.fetch_nostr:
        # R√©cup√©rer depuis NOSTR
        messages = asyncio.run(fetch_and_process_nostr_events(args.relay, args.limit))
    elif args.input:
        with open(args.input, 'r') as f:
            messages = json.load(f)
    else:
        # Lire depuis stdin
        messages = json.load(sys.stdin)
    
    # Grouper les vid√©os par cha√Æne
    channels = {}
    for message in messages:
        video_info = parse_nostr_message(message)
        channel_name = video_info.get('channel_name', 'unknown')
        
        if channel_name not in channels:
            channels[channel_name] = []
        
        channels[channel_name].append(video_info)
    
    # Cr√©er les playlists de cha√Ænes
    channel_playlists = {}
    for channel_name, videos in channels.items():
        channel_playlists[channel_name] = create_channel_playlist(videos, channel_name)
    
    # Afficher la sortie
    if args.channel and args.channel in channel_playlists:
        playlist = channel_playlists[args.channel]
        
        if args.format == 'json':
            output = json.dumps(playlist, indent=2, ensure_ascii=False)
        elif args.format == 'm3u':
            output = playlist['export_formats']['m3u']
        elif args.format == 'csv':
            output = playlist['export_formats']['csv']
        
        if args.output:
            with open(args.output, 'w') as f:
                f.write(output)
        else:
            print(output)
    else:
        # Afficher toutes les cha√Ænes disponibles
        print("Cha√Ænes disponibles:")
        for channel_name, playlist in channel_playlists.items():
            print(f"- {channel_name}: {playlist['channel_info']['video_count']} vid√©os")

if __name__ == "__main__":
    main()
